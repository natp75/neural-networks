{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d8aa36d0",
   "metadata": {},
   "source": [
    "# Введение в искусственные нейронные сети\n",
    "\n",
    "Урок 1. Основы обучения нейронных сетей\n",
    "Задание\n",
    "Попробуйте видоизменить параметры разобранной на уроке двухслойной нейронной сети таким образом, чтобы улучшить ее точность (число нейронов, число эпох , можно изменять число слоев).\n",
    "Проведите анализ — что приводит к ухудшению точности нейронной сети? Что приводит к увеличению ее точности?\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c353f2a",
   "metadata": {},
   "source": [
    "# Подготовка построения двухслойной нейронной сети на numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2029dcfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Исходный код к уроку 1.\n",
    "Построение двухслойной нейронный сети для классификации цветков ириса\n",
    "'''\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "# sklearn здесь только, чтобы разделить выборку на тренировочную и тестовую\n",
    "from sklearn.model_selection import train_test_split\n",
    "#   http://localhost:8888/edit/Iris.csv\n",
    "### Шаг 1. Определение функций, которые понадобяться для обучения\n",
    "# преобразование массива в бинарный вид результатов\n",
    "def to_one_hot(Y):\n",
    "    n_col = np.amax(Y) + 1\n",
    "    binarized = np.zeros((len(Y), n_col))\n",
    "    for i in range(len(Y)):\n",
    "        binarized[i, Y[i]] = 1.\n",
    "    return binarized\n",
    "\n",
    "# преобразование массива в необходимый вид\n",
    "def from_one_hot(Y):\n",
    "    arr = np.zeros((len(Y), 1))\n",
    "\n",
    "    for i in range(len(Y)):\n",
    "        l = layer2[i]\n",
    "        for j in range(len(l)):\n",
    "            if(l[j] == 1):\n",
    "                arr[i] = j+1\n",
    "    return arr\n",
    "\n",
    "# сигмоида и ее производная\n",
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "def sigmoid_deriv(x):\n",
    "    return sigmoid(x)*(1 - sigmoid(x))\n",
    "\n",
    "# нормализация массива\n",
    "def normalize(X, axis=-1, order=2):\n",
    "    l2 = np.atleast_1d(np.linalg.norm(X, order, axis))\n",
    "    l2[l2 == 0] = 1\n",
    "    return X / np.expand_dims(l2, axis)\n",
    "### Шаг 2. Подготовка тренировочных данных\n",
    "# получения данных из csv файла. укажите здесь путь к файлу Iris.csv\n",
    "iris_data = pd.read_csv(\"Iris.csv\")\n",
    "\n",
    "\n",
    "# замена текстовых значений на цифровые\n",
    "iris_data['Species'].replace(['Iris-setosa', 'Iris-virginica', 'Iris-versicolor'], [0, 1, 2], inplace=True)\n",
    "\n",
    "# формирование входных данных\n",
    "columns = ['SepalLengthCm', 'SepalWidthCm', 'PetalLengthCm', 'PetalWidthCm']\n",
    "x = pd.DataFrame(iris_data, columns=columns)\n",
    "x = normalize(x.values)\n",
    "\n",
    "# формирование выходных данных(результатов)\n",
    "columns = ['Species']\n",
    "y = pd.DataFrame(iris_data, columns=columns)\n",
    "y = y.values\n",
    "y = y.flatten()\n",
    "y = to_one_hot(y).argmax(axis=1)\n",
    "\n",
    "# Разделение данных на тренировочные и тестовые\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8bf995d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c4ab4048",
   "metadata": {},
   "source": [
    "#  Разработанная на уроке двухслойная сеть\n",
    "число нейронов скрытого слоя: 5\n",
    "число эпох: 300\n",
    "число слоев: 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6937e44e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (100,) (100,3) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-9c058d54d764>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[1;31m# обратное распространение(back propagation) с использованием градиентного спуска\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m     \u001b[0mlayer2_error\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my_train\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlayer2\u001b[0m \u001b[1;31m# производная функции потерь = производная квадратичных потерь\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m     \u001b[0mlayer2_delta\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayer2_error\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0msigmoid_deriv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (100,) (100,3) "
     ]
    }
   ],
   "source": [
    "### Шаг 3. Обученние нейронной сети\n",
    "\n",
    "# определим число нейронов скрытого слоя\n",
    "neuron_numb = 5\n",
    "\n",
    "# присваивание случайных весов\n",
    "w0 = 2*np.random.random((4, neuron_numb)) - 1 # для входного слоя   - 4 входа, 3 выхода\n",
    "w1 = 2*np.random.random((neuron_numb, 3)) - 1 # для внутреннего слоя - 5 входов, 3 выхода\n",
    "\n",
    "# скорость обучения (learning rate)\n",
    "n = 0.1\n",
    "\n",
    "# массив для ошибок, чтобы потом построить график\n",
    "errors = []\n",
    "\n",
    "# процесс обучения\n",
    "for i in range(300):\n",
    "\n",
    "    # прямое распространение(feed forward)\n",
    "    layer0 = X_train\n",
    "    layer1 = sigmoid(np.dot(layer0, w0))\n",
    "    layer2 = sigmoid(np.dot(layer1, w1))\n",
    "\n",
    "    # обратное распространение(back propagation) с использованием градиентного спуска\n",
    "    layer2_error = y_train - layer2 # производная функции потерь = производная квадратичных потерь \n",
    "    layer2_delta = layer2_error * sigmoid_deriv(layer2)\n",
    "    \n",
    "    layer1_error = layer2_delta.dot(w1.T)\n",
    "    layer1_delta = layer1_error * sigmoid_deriv(layer1)\n",
    "    \n",
    "    w1 += layer1.T.dot(layer2_delta) * n\n",
    "    w0 += layer0.T.dot(layer1_delta) * n\n",
    "    # метрика модели\n",
    "    error = np.mean(np.abs(layer2_error))\n",
    "    errors.append(error)\n",
    "    accuracy = (1 - error) * 100\n",
    "\n",
    "\n",
    "### Шаг 4. Демонстрация полученных результатов\n",
    "# черчение диаграммы точности в зависимости от обучения\n",
    "plt.figure(figsize = (16,5))\n",
    "plt.plot(errors)\n",
    "plt.xlabel('Обучение')\n",
    "plt.ylabel('Ошибка')\n",
    "plt.show() \n",
    "\n",
    "N = 50\n",
    "plt.figure(figsize = (16,5))\n",
    "plt.plot(layer2[:N,1], 'r',label = 'Y new')\n",
    "plt.plot(y_train[:N,1],'g', label = 'Y train')\n",
    "plt.xlabel('№ примера')\n",
    "plt.ylabel('выход сети и целевой')\n",
    "plt.legend( )\n",
    "plt.show() \n",
    "        \n",
    "print(\"Аккуратность нейронной сети \" + str(round(accuracy,2)) + \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "82dbfcb9",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (50,) (50,3) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-7dae2dce538f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mlayer1_t\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msigmoid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayer0_t\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mlayer2_t\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msigmoid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayer1_t\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mlayer2_error_t\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlayer2_t\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (50,) (50,3) "
     ]
    }
   ],
   "source": [
    "# прямое распространение(feed forward)\n",
    "layer0_t = X_test\n",
    "layer1_t = sigmoid(np.dot(layer0_t, w0))\n",
    "layer2_t = sigmoid(np.dot(layer1_t, w1))\n",
    "layer2_error_t = y_test - layer2_t\n",
    "    \n",
    "    \n",
    "N = 50\n",
    "plt.figure(figsize = (16,5))\n",
    "plt.plot(layer2_t[:N,1], 'r',label = 'Y new')\n",
    "plt.plot(y_test[:N,1],'g', label = 'Y train')\n",
    "plt.xlabel('№ примера')\n",
    "plt.ylabel('выход сети и целевой')\n",
    "plt.legend( )\n",
    "plt.show() \n",
    "\n",
    "# метрика модели\n",
    "error_t = np.mean(np.abs(layer2_error_t))\n",
    "accuracy_t = (1 - error_t) * 100\n",
    "print(\"Аккуратность нейронной сети на тесте \" + str(round(accuracy_t,2)) + \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ff3e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# прямое распространение(feed forward)\n",
    "layer0_t = X_test\n",
    "layer1_t = sigmoid(np.dot(layer0_t, w0))\n",
    "layer2_t = sigmoid(np.dot(layer1_t, w1))\n",
    "layer2_error_t = y_test - layer2_t\n",
    "    \n",
    "    \n",
    "N = 50\n",
    "plt.figure(figsize = (16,5))\n",
    "plt.plot(layer2_t[:N,1], 'r',label = 'Y new')\n",
    "plt.plot(y_test[:N,1],'g', label = 'Y train')\n",
    "plt.xlabel('№ примера')\n",
    "plt.ylabel('выход сети и целевой')\n",
    "plt.legend( )\n",
    "plt.show() # расскоментируйте, чтобы посмотреть\n",
    "\n",
    "# метрика модели\n",
    "error_t = np.mean(np.abs(layer2_error_t))\n",
    "accuracy_t = (1 - error_t) * 100\n",
    "print(\"Аккуратность нейронной сети на тесте \" + str(round(accuracy_t,2)) + \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c1c5d55",
   "metadata": {},
   "source": [
    "# 2. Построение нейронной сети при фиксированном числе нейронов скрытого слоя\n",
    "число нейронов скрытого слоя: 5\n",
    "число эпох: 300, 2700, 5100, 7500, 9900\n",
    "скорость обучения: 0.001, 0.01, 0.1, 1\n",
    "число слоев: 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1cb34d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.model_selection import cross_val_score, ShuffleSplit \n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "797cdcf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator\n",
    "\n",
    "class NN(BaseEstimator):\n",
    "    def __init__(self, iters=1, learning_rate=1):\n",
    "        self.iters = iters\n",
    "        self.learning_rate = learning_rate\n",
    "        self.w0 = 2*np.random.random((4, 5))\n",
    "        self.w1 = 2*np.random.random((5, 3))     \n",
    "        \n",
    "\n",
    "    def fit(self, X_train, y_train):\n",
    "        \n",
    "        self.errors = []\n",
    "        y_train = to_one_hot(y_train)\n",
    "        \n",
    "        for i in range(int(self.iters)):\n",
    "        \n",
    "            # прямое распространение(feed forward)\n",
    "            layer0 = X_train\n",
    "            layer1 = sigmoid(np.dot(layer0, self.w0))\n",
    "            layer2 = sigmoid(np.dot(layer1, self.w1))\n",
    "        \n",
    "            # обратное распространение(back propagation) с использованиемd градиентного спуска\n",
    "            layer2_error = y_train - layer2\n",
    "            layer2_delta = layer2_error * sigmoid_deriv(layer2)\n",
    "            \n",
    "            layer1_error = layer2_delta.dot(self.w1.T)\n",
    "            layer1_delta = layer1_error * sigmoid_deriv(layer1)\n",
    "            \n",
    "            self.w1 += layer1.T.dot(layer2_delta) * self.learning_rate\n",
    "            self.w0 += layer0.T.dot(layer1_delta) * self.learning_rate\n",
    "            \n",
    "            error = np.mean(np.abs(layer2_error))\n",
    "            self.errors.append(error)\n",
    "    \n",
    "    \n",
    "    def predict(self, X_test):\n",
    "        layer0 = X_test\n",
    "        layer1 = sigmoid(np.dot(layer0, self.w0))\n",
    "        layer2 = sigmoid(np.dot(layer1, self.w1))\n",
    "        return layer2.argmax(axis=1)\n",
    "    \n",
    "    # score - accuracy\n",
    "    def score(self, x, y):\n",
    "        layer0 = x\n",
    "        layer1 = sigmoid(np.dot(layer0, self.w0))\n",
    "        layer2 = sigmoid(np.dot(layer1, self.w1))\n",
    "        layer2_error = to_one_hot(y) - layer2\n",
    "        error = np.mean(np.abs(layer2_error))\n",
    "        accuracy = (1 - error) * 100\n",
    "        return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "662dc731",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "\n",
    "# сетка параметров\n",
    "rate_space = np.logspace(-3, 0, 4)\n",
    "iters_space = np.linspace(300,9900,5).astype(int)\n",
    "\n",
    "\n",
    "# кросс-валидатор\n",
    "cv = ShuffleSplit(n_splits=5, test_size=0.3, random_state=0)\n",
    "\n",
    "# счетчик для отображения прогресса\n",
    "counter_len = len(rate_space)*len(iters_space)\n",
    "counter = 0\n",
    "\n",
    "\n",
    "for learning_rate in rate_space:\n",
    "    for iters in iters_space:\n",
    "        \n",
    "        # отображение прогесса вычислений\n",
    "        counter += 1\n",
    "        print(f'{counter}/{counter_len} ({counter*100/counter_len:.1f}%)', end='\\r')\n",
    "        \n",
    "        # средний скор на кросс-валидации (score - accuracy)\n",
    "        mean_accuracy = cross_val_score(NN(iters, learning_rate), x, y, cv=cv).mean()\n",
    "        \n",
    "        # накопление результатов\n",
    "        result.append([learning_rate,iters, mean_accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b80290b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-3b7544b9ecc0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Лучшие оценки\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'learning rate'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'iters'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mascending\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "# Лучшие оценки\n",
    "pd.DataFrame(result, columns=['learning rate','iters','accuracy']).sort_values('accuracy',ascending=False).head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe66b41",
   "metadata": {},
   "source": [
    "# 3. Построение нейронной сети при фиксированной скорости обучения\n",
    "число нейронов скрытого слоя: 5, 20, 36, 52, 68, 84, 100\n",
    "число эпох: 300, 2700, 5100, 7500, 9900\n",
    "скорость обучения: 0.1\n",
    "число слоев: 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad47df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN_ni(BaseEstimator):\n",
    "    def __init__(self, iters=1, learning_rate=0.1, neurons=5):\n",
    "        self.iters = iters\n",
    "        self.learning_rate = learning_rate\n",
    "        self.neurons = neurons\n",
    "        self.w0 = 2*np.random.random((4, neurons))\n",
    "        self.w1 = 2*np.random.random((neurons, 3))     \n",
    "        \n",
    "\n",
    "    def fit(self, X_train, y_train):\n",
    "        \n",
    "        self.errors = []\n",
    "        y_train = to_one_hot(y_train)\n",
    "        \n",
    "        for i in range(int(self.iters)):\n",
    "        \n",
    "            # прямое распространение(feed forward)\n",
    "            layer0 = X_train\n",
    "            layer1 = sigmoid(np.dot(layer0, self.w0))\n",
    "            layer2 = sigmoid(np.dot(layer1, self.w1))\n",
    "        \n",
    "            # обратное распространение(back propagation) с использованиемd градиентного спуска\n",
    "            layer2_error = y_train - layer2\n",
    "            layer2_delta = layer2_error * sigmoid_deriv(layer2)\n",
    "            \n",
    "            layer1_error = layer2_delta.dot(self.w1.T)\n",
    "            layer1_delta = layer1_error * sigmoid_deriv(layer1)\n",
    "            \n",
    "            self.w1 += layer1.T.dot(layer2_delta) * self.learning_rate\n",
    "            self.w0 += layer0.T.dot(layer1_delta) * self.learning_rate\n",
    "            \n",
    "            error = np.mean(np.abs(layer2_error))\n",
    "            self.errors.append(error)\n",
    "    \n",
    "    \n",
    "    def predict(self, X_test):\n",
    "        layer0 = X_test\n",
    "        layer1 = sigmoid(np.dot(layer0, self.w0))\n",
    "        layer2 = sigmoid(np.dot(layer1, self.w1))\n",
    "        return layer2.argmax(axis=1)\n",
    "    \n",
    "    # score - accuracy\n",
    "    def score(self, x, y):\n",
    "        layer0 = x\n",
    "        layer1 = sigmoid(np.dot(layer0, self.w0))\n",
    "        layer2 = sigmoid(np.dot(layer1, self.w1))\n",
    "        layer2_error = to_one_hot(y) - layer2\n",
    "        error = np.mean(np.abs(layer2_error))\n",
    "        accuracy = (1 - error) * 100\n",
    "        return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d21069da",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-8fcfa2bfc50b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# сетка параметров\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mrate_space\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mneurons_space\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinspace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m7\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0miters_space\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinspace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m300\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m9900\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "result_ni = []\n",
    "\n",
    "# сетка параметров\n",
    "rate_space = [0.1]\n",
    "neurons_space = np.linspace(5,100,7).astype(int)\n",
    "iters_space = np.linspace(300,9900,5).astype(int)\n",
    "\n",
    "\n",
    "# кросс-валидатор\n",
    "cv = ShuffleSplit(n_splits=5, test_size=0.3, random_state=0)\n",
    "\n",
    "# счетчик для отображения прогресса\n",
    "counter_len = len(rate_space)*len(iters_space)*len(neurons_space)\n",
    "counter = 0\n",
    "\n",
    "\n",
    "for learning_rate in rate_space:\n",
    "    for neurons in neurons_space:\n",
    "        for iters in iters_space:\n",
    "        \n",
    "            # отображение прогесса вычислений\n",
    "            counter += 1\n",
    "            print(f'{counter}/{counter_len} ({counter*100/counter_len:.1f}%)', end='\\r')\n",
    "        \n",
    "            # средний скор на кросс-валидации (score - accuracy)\n",
    "            mean_accuracy = cross_val_score(NN_ni(iters, learning_rate, neurons), x, y, cv=cv).mean()\n",
    "        \n",
    "            # накопление результатов\n",
    "            result_ni.append([learning_rate,iters, neurons, mean_accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d720135",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-3db9d9e39fd5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Лучшие оценки\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult_ni\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'learning rate'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'iters'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'neurons'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mascending\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "# Лучшие оценки\n",
    "pd.DataFrame(result_ni, columns=['learning rate','iters','neurons','accuracy']).sort_values('accuracy',ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8efa7733",
   "metadata": {},
   "source": [
    "# Вывод\n",
    "\n",
    "В рассматриваемом примере с ростом числа эпох увеличивается точность нейронной сети. Увеличение числа нейронов (ширины) скрытого слоя до определенных значений увеличивает точность нейронной сети, а дальнейшее увеличение ширины слоя приводит к снижению точности."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c507b734",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc16340",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d18bcd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
